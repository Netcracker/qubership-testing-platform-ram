base.url=${ATP_RAM_URL}
server.port=8080
server.forward-headers-strategy=NATIVE
spring.resources.static-locations=file:./web/
atp-ram.web.root-page=web/index.html
logging.level.org.qubership.atp.ram=${LOG_LEVEL:INFO}
atp.ram.singleui.enabled=false
fixedRate.tr.in.milliseconds=${SCHEDULER_RATE_TR}
fixedRate.er.in.milliseconds=${SCHEDULER_RATE_ER}
timeout.after.finish.date.of.last.tr.ms=${TIMEOUT_AFTER_FINISH_DATE_OF_LAST_TR:1800000}
timeout.after.start.date.of.er.hours=${TIMEOUT_AFTER_START_DATE_OF_ER:24}
terminate.timeout.in.minutes=${TERMINATE_TIMEOUT_IN_MINUTES:60}
jointExecutionRequests.complete.period.cron=${JER_COMPLETE_PERIOD_IN_MINUTES:0 0/30 * * * ?}
jointExecutionRequests.complete.timeout.seconds=${JER_COMPLETE_TIMEOUT_IN_SECONDS:43200}
spring.mvc.pathmatch.matching-strategy=ant_path_matcher
##==================Undertow====================
#replacement="server.undertow.threads.io" on SpringBoot version 2.5.x
server.undertow.io-threads=${UNDERTOW_THREADS_IO:6}
#replacement="server.undertow.threads.worker" on SpringBoot version 2.5.x
server.undertow.worker-threads=${UNDERTOW_THREADS_WORKER:48}

##==================MongoDb=====================
mongodb.database=${RAM_DB}
mongodb.host=${MONGO_DB_ADDR}
mongodb.port=${MONGO_DB_PORT}
mongodb.user=${RAM_DB_USER}
mongodb.password=${RAM_DB_PASSWORD}

##==================GridFS======================
gridfs.database=${GRIDFS_DB}
gridfs.host=${GRIDFS_DB_ADDR}
gridfs.port=${GRIDFS_DB_PORT}
gridfs.user=${GRIDFS_DB_USER}
gridfs.password=${GRIDFS_DB_PASSWORD}
gridfs.chunk.size=${GRID_CHUNK_SIZE:1024}

##================Catalogue===================
catalogue.url=${CATALOGUE_URL}

##==================ATP=====================
atp.editor.link=https://atp-service-address/common/uobject.jsp?tab=_Editor&object=

##==================MailSettings=====================
mail.smtp.host=${MAIL_HOST}
mail.smtp.ssl.enable=${MAIL_SSL}
mail.smtp.port=25
mail.smtps.auth=false

##================MailSender======================
atp.mailsender.url=${MAIL_SENDER_URL:}

##================Kafka===========================
kafka.mails.enable=${KAFKA_MAILS_ENABLE:false}
kafka.mails.topic=${KAFKA_MAILS_TOPIC:mails}
kafka.mails.responses.enable=${KAFKA_MAILS_RESPONSES_ENABLE:false}
kafka.mails.responses.topic.name=${KAFKA_MAILS_RESPONSE_TOPIC_NAME:mail_responses}
kafka.mails.message.size=${KAFKA_MAILS_MESSAGE_SIZE:15728640}
kafka.mails.compression.type=lz4
kafka.mails.responses.group.id=atp-ram
kafka.fdr.enable=${KAFKA_FDR_ENABLE:false}
kafka.fdr.producer.topic.name=${KAFKA_FDR_PRODUCER_TOPIC_NAME:fdr}
kafka.fdr.consumer.topic.name=${KAFKA_FDR_CONSUMER_TOPIC_NAME:fdr-links}
kafka.rca.enable=${KAFKA_RCA_ENABLE:false}
kafka.rca.consumer.topic.name=${KAFKA_RCA_CONSUMER_TOPIC_NAME:rca}
kafka.project.event.enable=${KAFKA_PROJECT_EVENT_ENABLE:true}
kafka.test.plan.event.enable=${KAFKA_TEST_PLAN_EVENT_ENABLE:true}
kafka.project.event.consumer.topic.name=${KAFKA_PROJECT_EVENT_CONSUMER_TOPIC_NAME:catalog_notification_topic}
kafka.test.plan.consumer.topic.name=${KAFKA_TEST_PLAN_TOPIC_NAME:catalog_test_plan_topic}
kafka.enable=${KAFKA_ENABLE:false}
kafka.service.entities.topic=${KAFKA_SERVICE_ENTITIES_TOPIC:service_entities}
kafka.service.entities.topic.partitions=${KAFKA_SERVICE_ENTITIES_TOPIC_PARTITIONS:1}
kafka.service.entities.topic.replicas=${KAFKA_SERVICE_ENTITIES_TOPIC_REPLICATION_FACTOR:3}
kafka.notification.topic.name=${KAFKA_NOTIFICATION_TOPIC:notification_topic}
kafka.notification.topic.replicas=${KAFKA_NOTIFICATION_TOPIC_REPLICATION_FACTOR:3}
kafka.notification.topic.min.insync.replicas=${KAFKA_NOTIFICATION_TOPIC_MIN_INSYNC_REPLICATION_FACTOR:3}
kafka.notification.topic.partitions=${KAFKA_NOTIFICATION_TOPIC_PARTITIONS:1}
spring.kafka.bootstrap-servers=${KAFKA_SERVERS:kafka:9092}
spring.kafka.producer.bootstrap-servers=${KAFKA_SERVERS:kafka:9092}
spring.kafka.consumer.bootstrap-servers=${KAFKA_SERVERS:kafka:9092}
spring.kafka.consumer.group-id=${KAFKA_GROUP_ID:ram}
spring.kafka.consumer.value-deserializer=${KAFKA_VALUE_DESERIALIZER:org.springframework.kafka.support.serializer.JsonDeserializer}
spring.kafka.consumer.key-deserializer=${KAFKA_KEY_DESERIALIZER:org.springframework.kafka.support.serializer.JsonDeserializer}
spring.kafka.consumer.properties.spring.json.trusted.packages=${KAFKA_TRUSTED_PACKAGES:*}
spring.kafka.consumer.properties.spring.json.type.mapping=${KAFKA_TYPE_MAPPING:org.qubership.automation.receiver.rest.model.RamLink:org.qubership.atp.ram.tsg.model.FdrResponse}

#server.ssl.enabled=true
#server.ssl.keyStoreType=PKCS12
#server.ssl.key-store=./config/keystore.p12
#server.ssl.key-store-password=123456

##==================Zipkin=====================
spring.sleuth.enabled=${ZIPKIN_ENABLE:false}
spring.sleuth.sampler.probability=${ZIPKIN_PROBABILITY:1.0}
spring.zipkin.baseUrl=${ZIPKIN_URL:http://localhost:9411}
spring.sleuth.web.additional-skip-pattern=/rest/deployment/liveness|/rest/deployment/readiness
spring.sleuth.kafka.enabled=false
##==================atp-auth-spring-boot-starter=====================
# spring
spring.profiles.active=${SPRING_PROFILES:disable-security}
spring.main.allow-bean-definition-overriding=true
spring.cache.cache-names=projects
spring.cache.caffeine.spec=maximumSize=100, expireAfterAccess=120s, expireAfterWrite=120s
# keycloak
keycloak.enabled=${KEYCLOAK_ENABLED:false}
keycloak.auth-server-url=${KEYCLOAK_AUTH_URL}
keycloak.realm=${KEYCLOAK_REALM}
keycloak.resource=${KEYCLOAK_CLIENT_NAME}
keycloak.credentials.secret=${KEYCLOAK_SECRET}
keycloak.public-client=true
keycloak.ssl-required=external
keycloak.bearer-only=true
keycloak.cors=true
# atp-auth
atp-auth.project_info_endpoint=${PROJECT_INFO_ENDPOINT}
atp-auth.enable-m2m=${ENABLE_M2M:true}
atp-auth.ssl.certificate.verify=${SSL_VERIFY:false}
atp-auth.ssl.certificate.dir.path=${SSL_CERTIFICATE_PATH:classpath:ssl}
atp-auth.headers.content-security-policy=${CONTENT_SECURITY_POLICY:default-src 'self' *}
# tsg
tsg.receiver.url=${TSG_RECEIVER_URL:http://tshooter-fdr-test-service-address}
grayLog.url= ${GRAY_LOG_URL:http://graylog-service-address}

##==================Integration with Spring Cloud======================
spring.application.name=${SERVICE_NAME:atp-ram}
eureka.client.serviceUrl.defaultZone=${SERVICE_REGISTRY_URL:http://atp-registry-service:8761/eureka}
eureka.client.enabled=${EUREKA_CLIENT_ENABLED:false}
eureka.instance.preferIpAddress=true

# integration with ATP1
atp1.integration.enable=${ATP1_INTEGRATION_ENABLE:false}

##==================Mongo settings======================
max.connection.idle.time=${MAX_CONNECTION_IDLE_TIME:0}
min.connections.per.host=${MIN_CONNECTIONS_PER_HOST:40}
connections.per.host=${CONNECTIONS_PER_HOST:100}
limit.testresults.catalog.dashboard=${LIMIT_TESTRESULTS_CATALOG_DASHBOARD:70}
atp.logrecord.step.for.recalculating.topissues=${ATP_LOGRECORD_STEP_FOR_RECALCULATING_TOPISSUES:500}

## ================== Feign ========================
atp.service.internal=${ATP_INTERNAL_GATEWAY_ENABLED:false}
## catalogue
feign.atp.catalogue.url=${FEIGN_ATP_CATALOGUE_URL:}
feign.atp.catalogue.name=${FEIGN_ATP_CATALOGUE_NAME:ATP-CATALOGUE}
feign.atp.catalogue.route=${FEIGN_ATP_CATALOGUE_ROUTE:}
## datasets
feign.atp.datasets.url=${FEIGN_ATP_DATASETS_URL:}
feign.atp.datasets.name=${FEIGN_ATP_DATASETS_NAME:ATP-DATASETS}
feign.atp.datasets.route=${FEIGN_ATP_DATASETS_ROUTE:}
## datasets
feign.atp.environments.url=${FEIGN_ATP_ENVIRONMENTS_URL:}
feign.atp.environments.name=${FEIGN_ATP_ENVIRONMENTS_NAME:ATP-ENVIRONMENTS}
feign.atp.environments.route=${FEIGN_ATP_ENVIRONMENTS_ROUTE:}
## orchestrator
feign.atp.orchestrator.url=${FEIGN_ATP_ORCHESTRATOR_URL:}
feign.atp.orchestrator.name=${FEIGN_ATP_ORCHESTRATOR_NAME:ATP-ORCHESTRATOR}
feign.atp.orchestrator.route=${FEIGN_ATP_ORCHESTRATOR_ROUTE:}
## mail-sender
feign.atp.mailsender.url=${FEIGN_ATP_MAILSENDER_URL:}
feign.atp.mailsender.name=${FEIGN_ATP_MAILSENDER_NAME:ATP-MAIL-SENDER}
feign.atp.mailsender.route=${FEIGN_ATP_MAILSENDER_ROUTE:}
## users management
feign.atp.users.url=${FEIGN_ATP_USERS_URL:}
feign.atp.users.name=${FEIGN_ATP_USERS_NAME:ATP-USERS-BACKEND}
feign.atp.users.route=${FEIGN_ATP_USERS_ROUTE:}

feign.client.config.ATP-MAIL-SENDER.connectTimeout=${FEIGN_MAIL_SENDER_CONNECT_TIMEOUT:10000}
feign.client.config.ATP-MAIL-SENDER.readTimeout=${FEIGN_MAIL_SENDER_READ_TIMEOUT:10000}
feign.client.config.atp-orchestrator.connectTimeout=${FEIGN_ORCHESTRATOR_CONNECT_TIMEOUT:10000}
feign.client.config.atp-orchestrator.read-timeout=${FEIGN_ORCHESTRATOR_READ_TIMEOUT:30000}


##=============Feign timeout=================
feign.client.config.default.connectTimeout=${FEIGN_CONNECT_TIMEOUT:160000000}
feign.client.config.default.readTimeout=${FEIGN_READ_TIMEOUT:160000000}

##==================Monitoring=====================
management.server.port=${MONITOR_PORT:8090}
management.endpoints.web.exposure.include=${MONITOR_WEB_EXPOSE:prometheus,info,scheduledtasks}
management.health.hazelcast.enabled=false
management.endpoints.web.base-path=${MONITOR_WEB_BASE:/}
management.endpoints.web.path-mapping.prometheus=${MONITOR_WEB_MAP_PROM:metrics}
management.metrics.tags.application=${spring.application.name}
management.health.consul.enabled=${CONSUL_HEALTH_CHECK_ENABLED:false}
browser.monitoring.link=${BROWSER_MONITORING_LINK:https://dashboard-service-address/d/Zg25fjQ7z/browser-stats?orgId=3&var-cloud=atp-cloud&var-namespace=selenoid&var-pod=%{browser_pod}&from=%{from_timestamp}&to=%{to_timestamp}}
##=============Lock Manager========================
atp.lock.default.duration.sec=${LOCK_DEFAULT_DURATION_SEC:60}
atp.lock.retry.timeout.sec=${LOCK_RETRY_TIMEOUT_SEC:10800}
atp.lock.retry.pace.sec=${LOCK_RETRY_PACE_SEC:3}
atp.ram.services.issues_creating.lock.duration.sec=${ISSUES_CREATING_LOCK_DURATION_SEC:300}
atp.ram.services.executionrequestconfig.creating.lock.duration.sec=${EXECUTION_REQUEST_CONFIG_CREATING_LOCK_DURATION_SEC:300}

atp.ram.regexp.timeout.sec=${REGEXP_TIMEOUT:300}

hazelcast.cluster-name =${HAZELCAST_CLUSTER_NAME:atp-hc}
hazelcast.enable-caching =${HAZELCAST_ENABLE:false}
hazelcast.address =${HAZELCAST_ADDRESS:127.0.0.1:5701}
#==================locale resolver==================================
locale.resolver.lang=${LOCALE_RESOLVER:en}
##================== Scheduling periods ======================
files.cleanup.job.enable=${FILES_CLEANUP_JOB_ENABLE:true}
files.expiration.days.interval=${FILES_EXPIRATION_DAYS_INTERVAL:14}
files.expiration.schedule.interval=${FILES_EXPIRATION_SCHEDULE_INTERVAL:0 0 0 * * *}
execution.request.cleanup.job.cron=${EXECUTION_REQUEST_CLEANUP_JOB_CRON:10 10 5 * * *}
atp.expired.execution.requests.batch.size=${EXPIRED_EXECUTION_REQUESTS_BATCH_SIZE:500}
##=============ATP LOGGING========================
atp.logging.resttemplate.headers=${ATP_HTTP_LOGGING_HEADERS:true}
atp.logging.resttemplate.headers.ignore=${ATP_HTTP_LOGGING_HEADERS_IGNORE: }
atp.logging.feignclient.headers=${ATP_HTTP_LOGGING_HEADERS:true}
atp.logging.feignclient.headers.ignore=${ATP_HTTP_LOGGING_HEADERS_IGNORE: }
atp.logging.controller.headers=${ATP_HTTP_LOGGING_HEADERS:true}
atp.logging.controller.headers.ignore=${ATP_HTTP_LOGGING_HEADERS_IGNORE:}
atp.logging.controller.uri.ignore=${ATP_HTTP_LOGGING_URI_IGNORE:/deployment/readiness /deployment/liveness}
server.shutdown=graceful

##=================== Swagger =======================
springdoc.api-docs.enabled=${SWAGGER_ENABLED:true}
##=============Audit Logging=================
atp.audit.logging.enable=${AUDIT_LOGGING_ENABLE:false}
atp.audit.logging.topic.name=${AUDIT_LOGGING_TOPIC_NAME:audit_logging_topic}
atp.audit.logging.topic.partitions=${AUDIT_LOGGING_TOPIC_PARTITIONS:1}
atp.audit.logging.topic.replicas=${AUDIT_LOGGING_TOPIC_REPLICAS:3}
atp.reporting.kafka.producer.bootstrap-server=${KAFKA_REPORTING_SERVERS:kafka:9092}

## notification
feign.atp.notification.url=${FEIGN_ATP_NOTIFICATION_URL:}
feign.atp.notification.name=${FEIGN_ATP_NOTIFICATION_NAME:ATP-NOTIFICATION}
feign.atp.notification.route=${FEIGN_ATP_NOTIFICATION_ROUTE:/api/atp-notification/v1}

## =================Multipart files size============================
spring.servlet.multipart.max-file-size=${MAX_FILE_SIZE:200MB}
spring.servlet.multipart.max-request-size=${MAX_FILE_SIZE:200MB}

##===================EI GridFS==================
ei.gridfs.database=${EI_GRIDFS_DB:dbname}
ei.gridfs.host=${EI_GRID_DBHOST:gridfs.mongocluster.svc}
ei.gridfs.port=${EI_GRID_DBPORT:27017}
ei.gridfs.user=${EI_GRID_USER:user}
ei.gridfs.password=${EI_GRID_PASS:pass}
## ================== Feign ========================
## export-import
feign.atp.ei.url=${FEIGN_ATP_EI_URL:}
feign.atp.ei.name=${FEIGN_ATP_EI_NAME:ATP-EXPORT-IMPORT}
feign.atp.ei.route=${FEIGN_ATP_EI_ROUTE:api/atp-export-import/v1}

## ================ Javers =================
javers.springDataAuditableRepositoryAspectEnabled=${JAVERS_ENABLED:true}
atp.last.revision.count=${ATP_LAST_REVISION_COUNT:200}
atp.archive.cron.expression=${ATP_ARCHIVE_CRON_EXPRESSION:0 0 0 */7 * ?}
atp.archive.job.name=${ATP_ARCHIVE_JOB_NAME:atp-ram-archive-job}
atp.archive.job.limit-of-data=${ATP_ARCHIVE_LIMIT_OF_DATA:5000}
atp.archive.job.bulk-delete-count=${ATP_ARCHIVE_BULK_DELETE:500}

## =======================TTL Index ================================
atp.ram.logrecords.index.date-expire-sec=${LOG_RECORDS_DATE_EXPIRE_SECONDS:1209600}
atp.ram.context.variables.index.date-expire-sec=${LOG_RECORDS_CONTEXT_VARIABLES_DATE_EXPIRE_SECONDS:259200}
